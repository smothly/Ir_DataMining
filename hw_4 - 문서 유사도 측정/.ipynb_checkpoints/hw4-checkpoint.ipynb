{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\승호\\3학년 2학기(2018)\\정보검색과 데이터마이닝\\과제\\hw_4 - 문서 유사도 측정\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\USER\\Desktop\\승호\\3학년 2학기(2018)\\정보검색과 데이터마이닝\\과제\\hw_4 - 문서 유사도 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fnames 파일 읽어서 list 형태로 가지고 있자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "f = open(\"fnames.txt\", 'r')\n",
    "f_list = []\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    f_list.append(line[:-1])\n",
    "f.close()\n",
    "# f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\승호\\3학년 2학기(2018)\\정보검색과 데이터마이닝\\과제\\hw_4 - 문서 유사도 측정\\klt2010\\EXE\n"
     ]
    }
   ],
   "source": [
    "cd klt2010/EXE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) index2018.exe를 이용하여 각 텍스트 파일에 대한 인덱싱 파일을 만들자(색인어 추출)\n",
    "* 추가로 각 파일당 unique한 색인어만 들어간 all_unique_indexing.txt파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_unique_indexing파일 존재하면 삭제\n",
    "if os.path.exists(\"all_unique_indexing.txt\"):\n",
    "    os.remove(\"all_unique_indexing.txt\")\n",
    "f = open(\"all_unique_indexing.txt\", 'a')\n",
    "\n",
    "# 색인어파일 디렉토리 있으면 삭제\n",
    "if os.path.exists(\"색인어파일\"):\n",
    "    subprocess.call(\"rm -rf 색인어파일\")\n",
    "subprocess.call(\"mkdir 색인어파일\")\n",
    "\n",
    "for i in range(len(f_list)):\n",
    "    input_f_name = \"../../textfiles/\" + f_list[i]\n",
    "    output_f_name = \"./색인어파일/\" + str(i) + \".txt\"\n",
    "        \n",
    "    # 각 파일 indexing file 만듬\n",
    "    cmd_exe = \" \".join([\"index2018.exe\", input_f_name, output_f_name])\n",
    "    subprocess.call(cmd_exe)\n",
    "    \n",
    "    # 각 파일에 unique한 색인어 목록 all_unique_indexing.txt파일에 써주기\n",
    "    cmd_exe = \" \".join([\"wordcount.exe -new -uniq -i\", output_f_name, \"temp_unique_indexing.txt\"])\n",
    "    subprocess.call(cmd_exe)\n",
    "    f_read = open(\"temp_unique_indexing.txt\", 'r', encoding = \"ANSI\")\n",
    "    lines = f_read.readlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            f.write(line)\n",
    "        except:\n",
    "            print(\"encoding error\")\n",
    "    f_read.close()\n",
    "\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) 만든 인덱싱 파일과 wordcount.exe를 이용해서 모든 파일에 docid : (빈도수, 단어), (빈도수, 단어) 형태로 저장하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2', '08'], ['1', '120Gb'], ['1', '1600'], ['1', '1Gb'], ['3', '20'], ['2', '2003'], ['1', '20일'], ['2', '21'], ['2', '23'], ['1', '23일'], ['2', '25'], ['1', '25일'], ['3', '32'], ['3', '32비트'], ['1', '37'], ['2', '3D'], ['1', '3D게'], ['1', '3D게임'], ['1', '46'], ['24', '64'], ['16', '64비트'], ['1', '64비트급'], ['13', 'AMD'], ['6', 'CPU'], ['1', 'CPU개발계획'], ['1', 'DDR'], ['1', 'HDD'], ['2', 'HP'], ['2', 'IBM'], ['1', 'IBM도'], ['24', 'PC'], ['1', 'PC기종'], ['1', 'PC수요'], ['2', 'PC시장'], ['3', 'PC업체'], ['3', 'PC용'], ['1', 'XP'], ['1', 'bailh'], ['1', 'bailh@etnews.co.kr'], ['1', 'co'], ['1', 'etnews'], ['1', 'kr'], ['1', '가능성'], ['1', '감지'], ['1', '강조'], ['4', '개발'], ['1', '개발자'], ['1', '개발중'], ['1', '개선'], ['1', '거'], ['2', '것'], ['1', '게'], ['2', '게임'], ['1', '게임전문가'], ['1', '게재'], ['1', '결정'], ['1', '결정키'], ['2', '계획'], ['3', '고'], ['1', '고객'], ['1', '고성능'], ['1', '고성능PC'], ['1', '고속'], ['1', '고위'], ['1', '공동'], ['6', '관계자'], ['1', '관련'], ['1', '관심'], ['1', '관심도'], ['1', '구도'], ['2', '국내'], ['1', '규격'], ['1', '그래픽'], ['1', '기능'], ['1', '기대'], ['1', '기반'], ['2', '기술'], ['1', '기술개발'], ['2', '기존'], ['1', '기종'], ['1', '내년'], ['3', '내달'], ['1', '내달중'], ['1', '내장'], ['2', '다음달'], ['1', '대기'], ['1', '대기수요'], ['1', '대대적'], ['1', '대응'], ['2', '데'], ['1', '도'], ['1', '동시'], ['1', '동참'], ['6', '등'], ['1', '때문'], ['1', '마니아층'], ['2', '멀티미디어'], ['1', '멀티미디어환경'], ['1', '메모리'], ['1', '모바일'], ['1', '모바일기능'], ['1', '미국'], ['2', '미온적'], ['1', '미지수'], ['2', '반응'], ['1', '방증'], ['1', '방침'], ['1', '배일'], ['1', '배일한기자'], ['1', '버스'], ['1', '버전'], ['1', '보고'], ['1', '비상'], ['19', '비트'], ['1', '비트급'], ['1', '사이'], ['1', '사진'], ['3', '삼보'], ['3', '삼보컴퓨터'], ['3', '삼성'], ['3', '삼성전자'], ['1', '상용'], ['1', '상용화'], ['1', '서버'], ['1', '선점'], ['1', '설명'], ['2', '성능'], ['2', '세계'], ['2', '속도'], ['2', '수요'], ['1', '시간'], ['1', '시스템'], ['1', '시스템버스'], ['7', '시장'], ['1', '시장반응'], ['1', '시장전망'], ['1', '시제품'], ['1', '신문'], ['1', '신문게재일자'], ['7', '애슬론'], ['7', '애슬론64'], ['2', '양산'], ['1', '양산여부'], ['1', '업계'], ['1', '업그레이드'], ['4', '업체'], ['1', '엔드'], ['1', '여부'], ['1', '연내'], ['1', '연말'], ['1', '예상'], ['3', '예정'], ['1', '올해안'], ['3', '용'], ['1', '워크스테이션'], ['1', '윈도'], ['1', '윈도XP'], ['6', '이'], ['4', '인텔'], ['3', '일'], ['1', '일자'], ['1', '입력'], ['1', '입력시간'], ['1', '적'], ['1', '전개'], ['1', '전망'], ['2', '전문가'], ['1', '전세계'], ['1', '전세계적'], ['3', '전자'], ['1', '정도'], ['1', '제품'], ['1', '주요'], ['1', '지금'], ['2', '지원'], ['1', '진행'], ['1', '진행중'], ['2', '채택'], ['7', '출시'], ['1', '출시일'], ['3', '출시행사'], ['1', '충분'], ['3', '컴퓨터'], ['1', '태도'], ['1', '판단'], ['1', '퍼스레딩'], ['1', '평가'], ['1', '표준'], ['1', '표준규격'], ['3', '프로세서'], ['1', '하순'], ['2', '하이'], ['1', '하이엔드'], ['1', '하이퍼스레딩'], ['1', '한계'], ['1', '한기자'], ['1', '한차원'], ['2', '함'], ['3', '행사'], ['2', '현재'], ['1', '확산'], ['1', '환경'], ['1', '활용'], ['1', '회사'], ['1', '회의'], ['1', '회의적'], 24]\n"
     ]
    }
   ],
   "source": [
    "forward_indexing_table = dict()\n",
    "\n",
    "for i in range(len(f_list)):\n",
    "\n",
    "    max_tf = 0\n",
    "    \n",
    "    # word_count실행\n",
    "    f_name = \"./색인어파일/\" + str(i) + \".txt\"\n",
    "    cmd_exe = \" \".join([\"wordcount.exe -new -i\", f_name, f_name])\n",
    "    subprocess.call(cmd_exe)\n",
    "    \n",
    "    #파일 열어서 forward_indexing_table만들기\n",
    "    f = open(f_name, \"r\", encoding = \"ANSI\")\n",
    "    word_list = []\n",
    "    while True:\n",
    "        try:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            temp_list = line.split()\n",
    "            word_list.append(temp_list)\n",
    "            # 각 문서의 max_tf구하는 과정 후에 문서유사도에서 tf계산할 때 쓰임\n",
    "            if max_tf < int(temp_list[0]):\n",
    "                max_tf = int(temp_list[0])\n",
    "        except:\n",
    "            print(\"encoding - error\")\n",
    "    # key는 docid = i 고 value는 해당파일 word_list를 가진 dictionary로 만든다.\n",
    "    word_list.append(max_tf)\n",
    "    forward_indexing_table[i] = word_list.copy()\n",
    "    \n",
    "print(forward_indexing_table[2])\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3) wordcount.exe를 all_unique_indexing.txt(각 파일당 unique indexing list)에 이용하여 DF계산하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_f_name = \"word_df.txt\"\n",
    "cmd_exe = \" \".join([\"wordcount.exe -new -i\",\"all_unique_indexing.txt\", output_f_name])\n",
    "subprocess.call(cmd_exe)\n",
    "\n",
    "# word_df 파일을 wordcount하여서 각 색인어당 df계산 [색인어, df]\n",
    "f = open(\"word_df.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "df_table = dict()\n",
    "for line in lines:\n",
    "    try:\n",
    "        a = line.split()\n",
    "        df_table[a[1]] = a[0] \n",
    "    except:\n",
    "        pass\n",
    "# print(df_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4) <TID, DF> table 구성 (그냥 색인어 대신 TID를 넣어주면 된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_df_table = []\n",
    "index = 0\n",
    "for df in df_table.values():\n",
    "    tid_df_table.append((index, df))\n",
    "    index = index + 1\n",
    "# print(tid_df_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문서 유사도 계산을 위해 docid : [ (term, weight) , (term, weight)  ... ] 형태로 저장\n",
    "### weight = tf * idf\n",
    "### tf = 문서에서 단어 나온 횟수 / 문서에서 제일 많이 나온 단어횟수\n",
    "### idf = log(전체문서개수 / df(단어가 문서전체에 나온 횟수)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['08', 0.16405320001107243], ['120Gb', 0.2681061049494772], ['1600', 0.19344946039830824], ['1Gb', 0.2681061049494772], ['20', 0.1978145318584795], ['2003', 0.16797549258257127], ['20일', 0.1393126693928807], ['21', 0.15672246893224268], ['23', 0.2007662356710253], ['23일', 0.18146270737948403], ['25', 0.17422842474448078], ['25일', 0.14542114748420887], ['32', 0.3672548696651216], ['32비트', 0.6031385757941691], ['37', 0.15527067990355178], ['3D', 0.2953478967409407], ['3D게', 0.23922497242614615], ['3D게임', 0.23922497242614615], ['46', 0.14328392688472757], ['64', 4.036651245989082], ['64비트', 2.9034033180717445], ['64비트급', 0.2681061049494772], ['AMD', 2.0960317957182046], ['CPU', 0.915489449136918], ['CPU개발계획', 0.2681061049494772], ['DDR', 0.1645683278749772], ['HDD', 0.15527067990355178], ['HP', 0.21189385172306888], ['IBM', 0.19095098269966004], ['IBM도', 0.20104619193138967], ['PC', 1.5145655929593282], ['PC기종', 0.2681061049494772], ['PC수요', 0.2681061049494772], ['PC시장', 0.3363876038324235], ['PC업체', 0.4298517806541828], ['PC용', 0.6031385757941691], ['XP', 0.12638954738022073], ['bailh', 0.17216505940805862], ['bailh@etnews.co.kr', 0.17216505940805862], ['co', 0.0037777535275467585], ['etnews', 0.004367733886031537], ['kr', 0.0034858667530297347], ['가능성', 0.08061403535238283], ['감지', 0.17216505940805862], ['강조', 0.09049444340608906], ['개발', 0.12179400735520868], ['개발자', 0.11440279436139653], ['개발중', 0.16123321505524651], ['개선', 0.08877005939930346], ['거', 0.10189843634263243], ['것', 0.006536571507630166], ['게', 0.21034383990281508], ['게임', 0.19095098269966004], ['게임전문가', 0.2681061049494772], ['게재', 0.005192843356705692], ['결정', 0.10428003691929696], ['결정키', 0.2681061049494772], ['계획', 0.07250217595539665], ['고', 0.09863745264302695], ['고객', 0.06968219099957071], ['고성능', 0.13235208253191544], ['고성능PC', 0.23922497242614615], ['고속', 0.16819380191621175], ['고위', 0.16123321505524651], ['공동', 0.06862728233355862], ['관계자', 0.3103974169743107], ['관련', 0.031717635483998356], ['관심', 0.06692636589521467], ['관심도', 0.16819380191621175], ['구도', 0.16123321505524651], ['국내', 0.07060815503226697], ['규격', 0.1393126693928807], ['그래픽', 0.12370044233282193], ['기능', 0.0541145034057163], ['기대', 0.06529216951382794], ['기반', 0.05081711504910281], ['기술', 0.06487955899730004], ['기술개발', 0.1412510033776679], ['기존', 0.10581337873866159], ['기종', 0.19344946039830824], ['내년', 0.06371965584787598], ['내달', 0.39705624759574637], ['내달중', 0.21034383990281508], ['내장', 0.12638954738022073], ['다음달', 0.24234883284760766], ['대기', 0.18146270737948403], ['대기수요', 0.21034383990281508], ['대대적', 0.14767394837047035], ['대응', 0.09481930980949088], ['데', 0.09427013422736477], ['도', 0.07969824757243386], ['동시', 0.11337393550346438], ['동참', 0.20104619193138967], ['등', 0.01573366788889916], ['때문', 0.04225047997979864], ['마니아층', 0.23922497242614615], ['멀티미디어', 0.22086307373909933], ['멀티미디어환경', 0.2681061049494772], ['메모리', 0.1094951678757139], ['모바일', 0.09892097951004308], ['모바일기능', 0.2681061049494772], ['미국', 0.05081711504910281], ['미온적', 0.4784499448522923], ['미지수', 0.17216505940805862], ['반응', 0.22880558872279305], ['방증', 0.21034383990281508], ['방침', 0.07340490351356446], ['배일', 0.17216505940805862], ['배일한기자', 0.17216505940805862], ['버스', 0.17216505940805862], ['버전', 0.09481930980949088], ['보고', 0.07263327652326289], ['비상', 0.17216505940805862], ['비트', 3.2711361287531138], ['비트급', 0.23922497242614615], ['사이', 0.0968196939422559], ['사진', 0.12117441642380383], ['삼보', 0.457744724568459], ['삼보컴퓨터', 0.47443614864652434], ['삼성', 0.21562703968438987], ['삼성전자', 0.2550121705143768], ['상용', 0.10189843634263243], ['상용화', 0.1165400149608778], ['서버', 0.07499239710657572], ['선점', 0.11545770302740861], ['설명', 0.0622043373407562], ['성능', 0.1922843444785301], ['세계', 0.10486639885113533], ['속도', 0.17422842474448078], ['수요', 0.16030725102255025], ['시간', 0.015062582695293678], ['시스템', 0.04394371521862473], ['시스템버스', 0.2681061049494772], ['시장', 0.18979372313350043], ['시장반응', 0.23922497242614615], ['시장전망', 0.21034383990281508], ['시제품', 0.18146270737948403], ['신문', 0.0036315545471434564], ['신문게재일자', 0.005420738181894661], ['애슬론', 1.4073233435197279], ['애슬론64', 1.8767427346463406], ['양산', 0.2713743907032923], ['양산여부', 0.2681061049494772], ['업계', 0.03114879843531805], ['업그레이드', 0.1094951678757139], ['업체', 0.07468241891716923], ['엔드', 0.1645683278749772], ['여부', 0.11236987085433686], ['연내', 0.13746051261909598], ['연말', 0.11545770302740861], ['예상', 0.06280386806792701], ['예정', 0.1451933700279633], ['올해안', 0.19344946039830824], ['용', 0.31784077758460333], ['워크스테이션', 0.18146270737948403], ['윈도', 0.08711421237224039], ['윈도XP', 0.13746051261909598], ['이', 0.02091520051817841], ['인텔', 0.4576111774455861], ['일', 0.05759211336477399], ['일자', 0.005117154568105778], ['입력', 0.015642638466902347], ['입력시간', 0.01856604591239957], ['적', 0.09820871145340557], ['전개', 0.1187928158471393], ['전망', 0.04394371521862473], ['전문가', 0.1325299526940718], ['전세계', 0.0968196939422559], ['전세계적', 0.15258157485615298], ['전자', 0.07606830142587537], ['정도', 0.055106613767954574], ['제품', 0.04097950271757302], ['주요', 0.06250302440236505], ['지금', 0.09168500059125807], ['지원', 0.10921521161534953], ['진행', 0.07499239710657572], ['진행중', 0.13235208253191544], ['채택', 0.21021029277994224], ['출시', 0.44388505963999203], ['출시일', 0.2681061049494772], ['출시행사', 0.8043183148484316], ['충분', 0.15527067990355178], ['컴퓨터', 0.16607513061085907], ['태도', 0.19344946039830824], ['판단', 0.09481930980949088], ['퍼스레딩', 0.2681061049494772], ['평가', 0.07924779273475821], ['표준', 0.10347095000858439], ['표준규격', 0.2681061049494772], ['프로세서', 0.3711013269984658], ['하순', 0.2681061049494772], ['하이', 0.26155913773192696], ['하이엔드', 0.19344946039830824], ['하이퍼스레딩', 0.2681061049494772], ['한계', 0.11440279436139653], ['한기자', 0.17216505940805862], ['한차원', 0.2223305929216393], ['함', 0.10393005941222484], ['행사', 0.3635232492714115], ['현재', 0.0871228990809127], ['확산', 0.08398774629128564], ['환경', 0.07419109035958041], ['활용', 0.0662649763470359], ['회사', 0.05266927182288755], ['회의', 0.12638954738022073], ['회의적', 0.21034383990281508]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "doc_vector = dict()\n",
    "\n",
    "# forward_indexing_table을 이용하여 docid와 term과 빈도수가 담긴 튜플들을 가져와 weight를 계산하여 다시 저장한다.\n",
    "for docid, tid_tf_tuples in forward_indexing_table.items():\n",
    "    \n",
    "    word_list = []\n",
    "    \n",
    "    # 마지막은 max_tf니까 마지막 전까지 루프를 돌린다\n",
    "    for tuple in tid_tf_tuples[:-1]:\n",
    "        \n",
    "        # tuple[0]에는 빈도수, tid_tf_tuples[-1]는 max_tf \n",
    "        tf = int(tuple[0]) / tid_tf_tuples[-1]\n",
    "        \n",
    "        # int(df_table[tuple[1]])는 해당 단어의 df\n",
    "        idf = math.log(623 / int(df_table[tuple[1]]))\n",
    "        \n",
    "        weight = tf * idf\n",
    "        word_list.append([tuple[1], weight])\n",
    "        \n",
    "    doc_vector[docid] = word_list.copy()\n",
    "\n",
    "#docid가 2인 문서의 벡터를 보여주겠다. \n",
    "print(doc_vector[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코사인유사도를 이용하여 doc_index를 증가시키며  upper triangle 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "[0.005876797470635268, 0.0602602858346442, 1.0000000000000002, 0.005293992941346082, 0.003464489140433201, 0.003897878994536316, 0.008538554470876753, 0.003962144989739963, 0.02294459013118945, 0.0046314646592155815, 0.010294363914396495, 0.00628435848967139, 0.005531589587219683, 0.013381239067877967, 0.0012389080779814496, 0.008709711490983813, 0.008432519759540034, 0.006133089314112343, 0.008140105377934755, 0.004970235250243711, 0.015583814128961615, 0.011098660954714764, 0.005601111510363249, 0.002662488101547168, 0.006872074844804966, 0.002535221495717811, 0.004385140355336219, 0.01242943655093168, 0.0034867265244853153, 0.04801624006389232, 0.003975083645466602, 0.0062583829030792995, 0.0030706684724754398, 0.005768542063601767, 0.0059661120281832535, 0.0034717486208596634, 0.0050122398306121346, 0.01578925760115371, 0.0021274343084008874, 0.0030202256629096647, 0.0019543516735168283, 0.008335770617823283, 0.017737090999039744, 0.004967819923744139, 0.008189048141643644, 0.010670966071849001, 0.002554351516580534, 0.006038200104163073, 0.012039503080739132, 0.011120370373825409, 0.006492111079030428, 0.001211848496243561, 0.008467773791032664, 0.008050134770701515, 0.004588737997270008, 0.00356535711810238, 0.014353611600427996, 0.010939392117681421, 0.006092213844711669, 0.011368688369812356, 0.00543653754208657, 0.007603525992666761, 0.010085338816522299, 0.004937397877155002, 0.002697209253436418, 0.010596199506733841, 0.006246205844858382, 0.008820088981007355, 0.0033250163930745144, 0.0026497813287302127, 0.007179264255802787, 0.006245563099070483, 0.024271019429411466, 0.013237100321344088, 0.01601436306300168, 0.01715101844443904, 0.01639389458777156, 0.010384169483788813, 0.007939240914574413, 0.012816470072496342, 0.014372089720552862, 0.004498460372256482, 0.0023119955027933745, 0.027692951089418147, 0.03380507347483548, 0.08380623054189715, 0.009428535782603772, 0.00982023633793487, 0.011091474856254254, 0.017507642971704797, 0.0026329755866565142, 0.007600430425032694, 0.008388282866455501, 0.006770557653875932, 0.0116464455581425, 0.002016904434522697, 0.006608298028626988, 0.002598137121390295, 0.36385484031184473, 0.1598022962381622, 0.018648904927340414, 0.01285001608576955, 0.006385177501334868, 0.006362982155687143, 0.00925326161414229, 0.004629868019479122, 0.008377712184098423, 0.0014229820043929603, 0.011007961074425705, 0.007884317419542366, 0.0025161877322731428, 0.005217717350659634, 0.002791249325429573, 0.0021799487189918284, 0.004824232985325119, 0.0013231732459618778, 0.00374715747265429, 0.017494899660789914, 0.02466138863175884, 0.04719114863282843, 0.01552738781895205, 0.00812889851015705, 0.01810321685913973, 0.02401582856421181, 0.009560457243918572, 0.003709694634850387, 0.0060804525988295685, 0.005182750514795279, 0.013243798660000862, 0.010348488014830194, 0.0013958302372638922, 0.02781051561913689, 0.004573396417106694, 0.004436327660203752, 0.006891918141281642, 0.012367759172669706, 0.006399140739034146, 0.020024862838801727, 0.0230862148965918, 0.019980438064257165, 0.0037817066904432288, 0.007264185285775301, 0.0049044969368345955, 0.030765276178533748, 0.0030975999608406166, 0.0023090301284696695, 0.1279252810796339, 0.013059064435971152, 0.017286265286912725, 0.0027778817497964626, 0.004244555680224874, 0.0044890625063089195, 0.030420867179622172, 0.008013874400167174, 0.008805484743601813, 0.019888186671476158, 0.0901516356822057, 0.026244293510850874, 0.06591359356850493, 0.04539771936399534, 0.003442633246684391, 0.01134119400150687, 0.023787748576609827, 0.012859564605665062, 0.008110043020010968, 0.004038147870718291, 0.014862495995386069, 0.009042238880570597, 0.005737458924343179, 0.004395885160626875, 0.09901622199871427, 0.005438231357556038, 0.010937819697232938, 0.0009963106107127178, 0.06492066945830388, 0.046790860275958794, 0.043187762068782415, 0.0032829066042413197, 0.002038432473017287, 0.024964982707050228, 0.005876949553544452, 0.007009609996049686, 0.004059347321569251, 0.0019694937156853652, 0.023165351977860456, 0.004377403609660011, 0.003704632515610456, 0.008161096425633313, 0.004989534156173751, 0.006175803584989592, 0.26386798222693136, 0.05385946350080716, 0.04789262752153733, 0.00803842531748738, 0.01584535765204333, 0.030752485651855944, 0.024337861349159762, 0.055016039177454644, 0.003954846271212347, 0.005661039931565778, 0.004341018325436969, 0.003404910223791217, 0.007289401066546389, 0.02537498579407354, 0.013650430492563382, 0.01726280401300797, 0.007662486531791761, 0.011795043223676721, 0.0058738941161812445, 0.0017170785782654632, 0.004300342832597611, 0.003400513646389533, 0.001684268191855733, 0.003383516890799759, 0.0014512297879204247, 0.0015031129349392382, 0.004755538456311725, 0.0032259275721626683, 0.009391496595122967, 0.01957427386680646, 0.005393959400194435, 0.02585634828374323, 0.011680768136319887, 0.013030659969483223, 0.005431435475337099, 0.015880620037376662, 0.0013962961960138943, 0.005775747303792426, 0.009739026736362379, 0.008358648950760316, 0.004406794330924441, 0.004810751348190933, 0.011934834356348102, 0.003773220898221157, 0.006845539653534048, 0.005719878783537641, 0.06027176109396673, 0.00432087155798743, 0.004853315944150522, 0.008342562034745671, 0.004432592651778078, 0.008389805641611531, 0.0024333531894126137, 0.0022433689038689445, 0.011975865984624997, 0.002752481381123905, 0.006984339497666056, 0.0023922975240933905, 0.0078392750673213, 0.005583312767631436, 0.004307170377115046, 0.00826899219120101, 0.00354334446082302, 0.0044787728587979804, 0.004820734793813466, 0.00908457402378178, 0.003795519694765813, 0.003976407710127926, 0.49486281808441085, 0.008113525399540704, 0.0901387535547726, 0.05550876085829625, 0.012811767242261301, 0.007818557884156585, 0.020815890380752784, 0.009742499974197408, 0.022942677597865016, 0.058217061577444086, 0.002606875527961198, 0.008126657714521217, 0.07629121014535985, 0.011137527456590572, 0.004337250178143082, 0.006012476014159228, 0.01673974851946287, 0.011860688199914433, 0.006631938371887415, 0.005099412666483797, 0.00690932214387212, 0.009524585353880132, 0.0032211125721088554, 0.0050044496167556225, 0.0019371260590529947, 0.012521501870349352, 0.016961609611998402, 0.010496968812058824, 0.00814221484505988, 0.004929673411358933, 0.0053890827053879285, 0.16046575474889094, 0.0030639268635229313, 0.007152933754251264, 0.0030145603184111983, 0.003619067112212668, 0.0021337430508495446, 0.006616874890782725, 0.006204992818913784, 0.04532557147661919, 0.007404278374291493, 0.003299277084184746, 0.004966154937359643, 0.0036918937368134153, 0.0028589855066490804, 0.003704057261178025, 0.004070512954699353, 0.01895848939046047, 0.030072820454700663, 0.012047695823881141, 0.005076744488283953, 0.009029756053262596, 0.02030183302414996, 0.03369549390718798, 0.12862957472924955, 0.005829786219755183, 0.007267856010510103, 0.00894206250680758, 0.01464595129406023, 0.005048586266895278, 0.006995392020585008, 0.008144946719867548, 0.009774245164970892, 0.005373796750118028, 0.19990701595144852, 0.005092856686508622, 0.004987542315792455, 0.00639574925257995, 0.004011945211387032, 0.004876098460457813, 0.002785332861776063, 0.005886808086741892, 0.0032730377802779806, 0.006642418151679779, 0.003908549772612861, 0.00601019796291329, 0.012542974261588376, 0.015698978623951493, 0.013728626951650351, 0.008367688287185412, 0.016192679440479908, 0.030902441016409894, 0.005523341440504187, 0.0072431007670811275, 0.010814114498907635, 0.059268661052723375, 0.005547191521237685, 0.001973411788751953, 0.0188348932934976, 0.013153851287075182, 0.023103453640316407, 0.010064040064611045, 0.007439296942661836, 0.004822243599038699, 0.004081839691413126, 0.0028102559587740664, 0.007324132824602976, 0.006420266870063274, 0.007222020902656492, 0.008471345995020783, 0.002707241824387134, 0.0030000650196679037, 0.010001438494839766, 0.007370738274178526, 0.003928782814215126, 0.011067588136650597, 0.0037398312633991414, 0.0021252630610191243, 0.0063162492093301395, 0.003137937131434458, 0.007282352635891662, 0.013730678303208779, 0.018839437939226312, 0.02870258751056732, 0.007100697652957051, 0.017009031346052823, 0.005320075836685693, 0.007899525205237793, 0.015497136632186397, 0.007056276674961508, 0.022276877833432827, 0.016182178837832736, 0.1438170982462365, 0.005657884456894528, 0.0008364344226023013, 0.017372412930829827, 0.01847508960044297, 0.008693172836612462, 0.010365077114292935, 0.010785012428996543, 0.016636400473659795, 0.003653872588126952, 0.005890637592786891, 0.022291576129625977, 0.02920393198098686, 0.04699128870868084, 0.023894918050929914, 0.006089979664823517, 0.00540151580003147, 0.39218756800992294, 0.014098818473709978, 0.01580506340117978, 0.01594884303182676, 0.003473937546147382, 0.0038929240234367828, 0.0018121109199608272, 0.008619849956087224, 0.0036504049486641103, 0.005528389423688774, 0.005954756221314475, 0.054848662065940905, 0.02896817431546375, 0.05860359938927511, 0.009891013543022721, 0.008174339737645043, 0.007722886567521568, 0.008765035279214385, 0.017779711845256983, 0.004364207684759781, 0.010451236896190383, 0.005322536043673737, 0.034711084588382006, 0.06540502442012094, 0.0100037331409165, 0.0028975013306449305, 0.00638310033439218, 0.006392638620635876, 0.007084472043159517, 0.01040531457684958, 0.019093415296626715, 0.00827816564913816, 0.003536079183884767, 0.006860158396864863, 0.0025823998187791135, 0.0036199430513389344, 0.0011732749970571174, 0.0040395906869279815, 0.006758158081855356, 0.021135598904284552, 0.0076078613980061025, 0.0048285399802029, 0.006948373807737955, 0.006768404149005039, 0.007983412465097157, 0.027846148253832026, 0.003662584119673801, 0.003336644772941898, 0.009428514698332271, 0.008273827321814753, 0.0015059653242593556, 0.002715495895808713, 0.009333594016884826, 0.006314641701443888, 0.012983681998026048, 0.006964728958578999, 0.009331083893977903, 0.006000104789026232, 0.0055576341794348165, 0.005911302699871879, 0.003442153364997876, 0.013668759524517111, 0.008605634855430304, 0.00948416560904283, 0.0050116580908057375, 0.005773334704117715, 0.008568347530881615, 0.010963609685496657, 0.009133407238441665, 0.003653787594744056, 0.004175832132157477, 0.004540887640614086, 0.006489350570476682, 0.005124665593097011, 0.004399859050021129, 0.016050822473924146, 0.011336500867640771, 0.009251918160610861, 0.014162841868514502, 0.007618500589456576, 0.019619320274867326, 0.014296129631008176, 0.05046863942843309, 0.010813485689902341, 0.009558327228179944, 0.014641136840159276, 0.008794165260495203, 0.006068827172528235, 0.018769945694882308, 0.0050867394317366315, 0.005068477407813599, 0.004745852124884231, 0.005972685406223128, 0.007823158799458895, 0.04171895153458987, 0.006126715998381549, 0.007855801689278887, 0.006321177080305111, 0.009033397140002473, 0.014677391366483697, 0.005845202781021662, 0.01311833383363226, 0.004623090764409242, 0.005033491494644279, 0.0031202660154938497, 0.00976873579160327, 0.016184598646133513, 0.06336501672052434, 0.007673331290660761, 0.04987405724128165, 0.0029423619589105743, 0.049193416031788145, 0.032257916354205225, 0.03744404064344571, 0.08247443141745579, 0.036225404822926, 0.042207800325940875, 0.01304389902140058, 0.011067066546542303, 0.010255709428985607, 0.012902620034633149, 0.02280770736862768, 0.020957132506240813, 0.003352736254294226, 0.0061136274315287086, 0.005485930281494882, 0.0062774062956191725, 0.004131236512506057, 0.013999165986060696, 0.004522154145303367, 0.005355947210768949, 0.0033300008584011935, 0.007916134020425868, 0.10178926627614514, 0.0038789551154508415, 0.0026241829218478195, 0.0035835825026136036, 0.008906337549703913, 0.005664857645096415, 0.015267284828867852, 0.017304384602719092, 0.002185698122613448, 0.005495684066916192, 0.06436851288841729, 0.025692736090385204, 0.006523586226129921, 0.002770210071671794, 0.006921904033934116, 0.005137074719024339, 0.016028442910431977, 0.006772473694856809, 0.0038626989921262006, 0.0037911571573597796, 0.01918737653818083, 0.005769666522116038, 0.004444244314223882, 0.009650897646286764, 0.005256514250455015, 0.005961802916659161, 0.0031854818333782466, 0.000684876555571359, 0.009155984434600294, 0.001741248623790211, 0.006920903812121363, 0.005788142177554809, 0.010277639654795272, 0.013483370593952366, 0.0118884145727332, 0.005878522259640811, 0.008390326426870745, 0.00950223847374482, 0.021811166175030042, 0.00906378931884255, 0.023056726879462346, 0.003942548244712092, 0.005670896561271488, 0.0057796381631783555, 0.0015917211432830657, 0.006078814782410041, 0.007410628043823486, 0.009448548777751321, 0.009562962344669738, 0.006795374777556422, 0.019715857024773964, 0.008106741381856445, 0.021518344523798354, 0.010045507813564725, 0.008017694047396115, 0.0035590812539287005, 0.00858543852376534, 0.013346785735205167, 0.00324052647542488, 0.00807117324375455, 0.006533567592868083, 0.0033614413139441087, 0.006378731855424105, 0.016122769379501856, 0.005437241016407554, 0.0045728244407995874, 0.006502183197672975, 0.014520201408945556, 0.006851880152863401, 0.03716113364663421, 0.006172196979822004, 0.013900994971046162, 0.00761893692265165, 0.003420774551673374, 0.01118707687521799, 0.005629467911392779, 0.011810506281696736, 0.011184638280692275, 0.0031963458800898605, 0.00462542610916031, 0.00291045039187209, 0.012802409836370345, 0.004651181016982724, 0.049477331510856995, 0.0783058794579723, 0.013131686672396533, 0.011280458844658198, 0.11064344645952061, 0.011672237642940984, 0.009791027629169793, 0.0032607915418819008, 0.0038385858088083725, 0.014603881318252205]\n"
     ]
    }
   ],
   "source": [
    "doc_index = 0\n",
    "\n",
    "similarity_matrix = []\n",
    "\n",
    "# 623개를 돌려야한다\n",
    "for a_index, weight_tuples in doc_vector.items():\n",
    "    \n",
    "    # 오래걸려서 몇번 문서까지 진행되는지 확인하는 프린트문\n",
    "    print(a_index)\n",
    "    \n",
    "    # 기준이 되는 문서의 weight의 합을 구하자! : 첫번째 분모 = a_denominator\n",
    "    a_denominator = 0\n",
    "    for tuple in weight_tuples:\n",
    "        a_denominator += math.pow(tuple[1], 2)\n",
    "    \n",
    "    # doc_index를 증가시키며 upper triangle형태로 만든다\n",
    "    temp_similarity = []\n",
    "    for b_index in range(doc_index, 623):\n",
    "        b_denominator = 0\n",
    "        # 비교할 문서의 weight의 합을 구하자! : 두번째 분모 b_denominator\n",
    "        for tuple in doc_vector[b_index]:\n",
    "            b_denominator += math.pow(tuple[1], 2)\n",
    "        # a * b 로 분모 구성 완료 \n",
    "        denominator = math.sqrt(a_denominator) * math.sqrt(b_denominator)\n",
    "        \n",
    "        # 각 term의 weight곱의 합을 구해야한다!\n",
    "        numerator = 0\n",
    "        for a_tuple in weight_tuples:\n",
    "            for b_tuple in doc_vector[b_index]:\n",
    "                if a_tuple[0] == b_tuple[0]:\n",
    "                    numerator += a_tuple[1] * b_tuple[1]\n",
    "#                    print(a_tuple, b_tuple)\n",
    "                    break\n",
    "        similarity = numerator / denominator\n",
    "        temp_similarity.append(similarity)\n",
    "    \n",
    "#     doc_index += 1\n",
    "    similarity_matrix.append(temp_similarity.copy())\n",
    "    \n",
    "print(similarity_matrix[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\승호\\3학년 2학기(2018)\\정보검색과 데이터마이닝\\과제\\hw_4 - 문서 유사도 측정\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\USER\\Desktop\\승호\\3학년 2학기(2018)\\정보검색과 데이터마이닝\\과제\\hw_4 - 문서 유사도 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과를 csv 파일에 쓰기\n",
    "### 623 X 623 매트릭스를 print하기 힘들어 csv파일에 써주겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "f = open('output.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(f)\n",
    "\n",
    "zero_count = 0\n",
    "for similarity_vector in similarity_matrix:\n",
    "    # 0번인덱스부터 채웠기 때문에 upper triangle로 만들어줄려면 앞에 0으로 채워줘야한다.\n",
    "    row = ([0] * zero_count) + (similarity_vector[zero_count:])\n",
    "#     row = similarity_vector\n",
    "    csv_writer.writerow(row)\n",
    "    zero_count += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의의 문서 x 와 제일 유사도가 높은 문서는?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 문서 x 숫자를 입력해주세요. (0 ~ 622)8\n",
      "가장 유사도가 높은 문서번호 :  9 , 유사도 :  0.5472360332114795\n",
      "IT-baidu.txt 와 제일 유사도가 높은 문서는  IT-2007newWebIR.txt 이다.\n"
     ]
    }
   ],
   "source": [
    "x = int(input('임의의 문서 x 숫자를 입력해주세요. (0 ~ 622)'))\n",
    "\n",
    "# x를 제외하고 max를 찾는 이유는 x index에는 자기 자신과의 유사도라 무조건 max이기 때문이다.\n",
    "similarity_value = max(similarity_matrix[x][:x] + similarity_matrix[x][x+1:])\n",
    "\n",
    "# similarity_value로 index를 찾아 doc_number를 찾는다\n",
    "doc_number = similarity_matrix[x].index(similarity_value)\n",
    "\n",
    "print('가장 유사도가 높은 문서번호 : ', doc_number ,', 유사도 : ', similarity_value)\n",
    "\n",
    "# 처음에 만들었는 file name list를 활용하여 예쁘게 출력해본다.\n",
    "print(f_list[x], '와 제일 유사도가 높은 문서는 ', f_list[doc_index], '이다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과제를 통하여 간단하게 문서유사도 계산을 만들었다. 분석하는 재미가 있었다. 하지만 실제로 유사도 계산 프로그램을 만들면 이렇게 만들면 안될 것 같다. 개선해야 할 점들을 정리해보겟다.\n",
    "\n",
    "개선해야할 점\n",
    "\n",
    "term말고 tid를 활용하여 저장공간과 효율적인 접근 가능하게 하기\n",
    "\n",
    "tf의 정의가 여러가지 있음.\n",
    "1. 그냥 빈도수,\n",
    "2. 빈도수 / 문서의 전체 빈도수의 합\n",
    "3. 빈도수 / 문서에서 가장 큰 빈도수\n",
    "4. 로그변환 드등 \n",
    "이거에 따라 유사도 값이 달라지는 것을 알아야 할듯...\n",
    "\n",
    "623개의 문서뿐만 아니라 어떤 데이터 셋이 txt파일로 와도 될수 있게 바꾸기\n",
    "ex) 623 -> len(f_list)등등\n",
    "\n",
    "loop횟수 줄이기 - 효율성, 알고리즘적 측면\n",
    "weight를 구하는 부분에서 너무오래걸린다.\n",
    "딕셔너리를 ordered되게해서 접근이 쉽게 만들기\n",
    "서로 공통된 단어들을 갖고있는 벡터를 만들어 weight계산을 빠르게 만들어주기\n",
    "각 문서의 weight들의 합 즉, 분모를 구성하는 걸 전에 loop돌릴 때 계산해서 값을 미리 저장해 놓는 것!\n",
    "등등 시간복잡도를 개선해야 할 부분들이 많이 보였다.\n",
    "\n",
    "623개의 문서만 하여 ram이 부족하진 않았지만, 실제로 큰 데이터 셋을 마주하게 되면\n",
    "file i/o를 통하여 프로그램을 만들어야 할 것 같다.\n",
    "그래서 csv파일 출력을 시도해 보았다.\n",
    "\n",
    "교수님께서 제공해주신 wordcount, index 실행파일도 좋지만, scikit learn 알고리즘이나 konlpy등 \n",
    "공개된 라이브러리를 이용하여 stemming, stopword처리부분을 활용하면 내가 원하는 결과를 얻을 수 있을 것 같다.\n",
    "\n",
    "나중에 텍스트 분석이나 검색엔진 구현작업을 하게 되면 도움이 될 수 있는 유용한 과제였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
